{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNcF0Rz0HspI188a5bW9dz3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SVT23/Text-Mining-and-Language-/blob/main/TM_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TOPIC MODELING"
      ],
      "metadata": {
        "id": "5FjOm2EkrlH2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Topic modeling allows us to automatically dsicover topics from a collection of documents. \n",
        "\n",
        "Shown below in code is basic python imports. Gets other libraries. "
      ],
      "metadata": {
        "id": "ix0zTB9ksNiz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fUzBuqParjhG"
      },
      "outputs": [],
      "source": [
        "import pandas as pd \n",
        "import numpy as np \n",
        "import nltk\n",
        "from nltk.tokenize import RegexpTokenizer \n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.decomposition import LatentDirichletAllocation \n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# COVID SURVEY DATASET"
      ],
      "metadata": {
        "id": "Z8Z8EPtUszR7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read data from CSV file \n",
        "covid_survey = pd.read_csv('COVIDSurveydata.csv')\n",
        "# filter data by text_long column \n",
        "covid_survey['text_long']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GPcIun-mvsem",
        "outputId": "c4a4924a-7f4c-400b-a058-21c07a8fc79f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       It is less an much an issue of how it affects ...\n",
              "1       I am concerned that the true impact of the cur...\n",
              "2       Personally, I am fairly calm about the corona ...\n",
              "3       In this very moment as I am fortunate to be ab...\n",
              "4       I am more worried about getting access to my n...\n",
              "                              ...                        \n",
              "2478    I feel sad for the loss of life and the pain t...\n",
              "2479    I fear  that  the virus is more deadly than  w...\n",
              "2480    I feel stressed and anxious about people ignor...\n",
              "2481    It is quite worrying even though it said to ha...\n",
              "2482    I feel helpless that in reality there's nothin...\n",
              "Name: text_long, Length: 2483, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# VECTORIZE THE DATA\n"
      ],
      "metadata": {
        "id": "_kD1QNtFR9NV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Vectorize survey using TF-IDF\n",
        "tfidf_vectorizer = TfidfVectorizer(lowercase=True,\n",
        "                            ngram_range = (1,2),\n",
        "                            #max_df=0.95, min_df=2, \n",
        "                            #max_features=n_features, \n",
        "                            stop_words=\"english\"\n",
        ")\n",
        "\n",
        "# Fit and Transform the documents\n",
        "X = tfidf_vectorizer.fit_transform(covid_survey['text_long'])  \n",
        "\n",
        "# get the actual words from the vectorized data\n",
        "tf_feature_names = tfidf_vectorizer.get_feature_names_out()\n",
        "\n",
        "print(\"n_samples: %d, n_features: %d\" % X.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vZFrpK6nSE2U",
        "outputId": "2783b76d-2471-45f2-db8f-c451f924391f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_samples: 2483, n_features: 82254\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PERFORM LDA"
      ],
      "metadata": {
        "id": "GvuapIukWoCH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the number of TOPICS or components\n",
        "# LDA topic modeling with 5 topics \n",
        "num_components=5\n",
        "\n",
        "# Create LDA object\n",
        "ldamodel=LatentDirichletAllocation(n_components=num_components)\n",
        "\n",
        "# Fit and Transform model on data that has already been vectorized\n",
        "lda_matrix = ldamodel.fit_transform(X)\n",
        "\n",
        "# Get Components from the lda model\n",
        "# components_[i, j] can be viewed as pseudocount that represents the number of \n",
        "# times word j was assigned to topic i. from scikit-learn\n",
        "lda_components=ldamodel.components_"
      ],
      "metadata": {
        "id": "hz05Cu1DWtZK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# view the topic models\n",
        "n_top_words = 10 # how many words per topic\n",
        "\n",
        "for i, topic in enumerate(lda_components):\n",
        "    # numpy argsort: Returns the indices that would sort an array\n",
        "    # we want the last n_top_words indices, as they have the highest counts \n",
        "    \n",
        "    top_features_index = topic.argsort() [  :-n_top_words - 1 : -1 ]\n",
        "\n",
        "    # based on indices, get the words, from the vectorizer features\n",
        "    top_features = [tf_feature_names[i] for i in top_features_index]\n",
        "    print('topic', i, top_features)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oj2TjI2BYHK5",
        "outputId": "3b8d77e0-e27e-4797-d291-f2fbcf831de9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "topic 0 ['feel', 'people', 'worried', 'family', 'situation', 'time', 'anxious', 'virus', 'home', 'going']\n",
            "topic 1 ['feel', 'people', 'family', 'situation', 'worried', 'virus', 'time', 'going', 'anxious', 'know']\n",
            "topic 2 ['feel', 'people', 'worried', 'situation', 'family', 'work', 'time', 'home', 'virus', 'anxious']\n",
            "topic 3 ['feel', 'people', 'worried', 'family', 'situation', 'time', 'work', 'anxious', 'home', 'virus']\n",
            "topic 4 ['feel', 'people', 'family', 'worried', 'time', 'home', 'virus', 'situation', 'anxious', 'like']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **UNIGRAM**"
      ],
      "metadata": {
        "id": "mWZ3ch5fXTGs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.util import ngrams \n",
        "covid_survey = pd.read_csv('COVIDSurveydata.csv')\n",
        "covid_survey['text_long']\n",
        "n = 1\n",
        "unigrams = ngrams(covid_survey, n)\n",
        "for item in unigrams: \n",
        "  print(item)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HUqOfYJ8Xahq",
        "outputId": "16aace75-8911-41b5-8712-e320d66f7010"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('Unnamed: 0',)\n",
            "('V1',)\n",
            "('worry',)\n",
            "('chosen_emotion',)\n",
            "('anger',)\n",
            "('disgust',)\n",
            "('fear',)\n",
            "('anxiety',)\n",
            "('sadness',)\n",
            "('happiness',)\n",
            "('relaxation',)\n",
            "('desire',)\n",
            "('text_long',)\n",
            "('timing_textlong_firstclick',)\n",
            "('timing_textlong_lastclick',)\n",
            "('timing_textlong_submit',)\n",
            "('timing_textlong_nclicks',)\n",
            "('text_short',)\n",
            "('timing_textshort_firstclick',)\n",
            "('timing_textshort_lastclick',)\n",
            "('timing_textshort_submit',)\n",
            "('timing_textshort_nclicks',)\n",
            "('self_rating_general',)\n",
            "('self_rating_short',)\n",
            "('self_rating_long',)\n",
            "('twitter_general_often',)\n",
            "('twitter_tweet_often',)\n",
            "('twitter_participate_often',)\n",
            "('eng_native',)\n",
            "('ntok_long',)\n",
            "('nchar_long',)\n",
            "('ntok_short',)\n",
            "('nchar_short',)\n",
            "('cld_lang_long',)\n",
            "('cld_lang_short',)\n",
            "('id',)\n",
            "('n_punct',)\n",
            "('prop_punct',)\n",
            "('age',)\n",
            "('Country of Birth',)\n",
            "('Current Country of Residence',)\n",
            "('Employment Status',)\n",
            "('First Language',)\n",
            "('Nationality',)\n",
            "('Sex',)\n",
            "('Social-Media',)\n",
            "('Student Status',)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "\n",
        "# TRIGRAM"
      ],
      "metadata": {
        "id": "OMQC1MbUeiiw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.util import ngrams \n",
        "covid_survey = pd.read_csv('COVIDSurveydata.csv')\n",
        "covid_survey['text_long']\n",
        "n = 3\n",
        "unigrams = ngrams(covid_survey, n)\n",
        "for item in unigrams: \n",
        "  print(item)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "_8LXzoFXepyx",
        "outputId": "f73722dd-3618-427e-a8dd-72fbf290f5c8"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-f0a1bd83fad7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mngrams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcovid_survey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'COVIDSurveydata.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mcovid_survey\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text_long'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0munigrams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mngrams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcovid_survey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GENDER"
      ],
      "metadata": {
        "id": "BXZesB8_mMzJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read data from CSV file \n",
        "covid_survey = pd.read_csv('COVIDSurveydata.csv')\n",
        "# filter data by Sex column \n",
        "covid_survey['Sex']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nw2tNQwymTV6",
        "outputId": "4e62c0ca-e896-4af4-e6c3-c34d4f947d81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0          NaN\n",
              "1          NaN\n",
              "2          NaN\n",
              "3       Female\n",
              "4       Female\n",
              "         ...  \n",
              "2478       NaN\n",
              "2479       NaN\n",
              "2480       NaN\n",
              "2481       NaN\n",
              "2482       NaN\n",
              "Name: Sex, Length: 2483, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    }
  ]
}