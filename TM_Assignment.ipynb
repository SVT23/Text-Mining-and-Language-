{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNcF0Rz0HspI188a5bW9dz3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SVT23/Text-Mining-and-Language-/blob/main/TM_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TOPIC MODELING"
      ],
      "metadata": {
        "id": "5FjOm2EkrlH2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Topic modeling allows us to automatically dsicover topics from a collection of documents. \n",
        "\n",
        "Shown below in code is basic python imports. Gets other libraries. "
      ],
      "metadata": {
        "id": "ix0zTB9ksNiz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "fUzBuqParjhG"
      },
      "outputs": [],
      "source": [
        "import pandas as pd \n",
        "import numpy as np \n",
        "import nltk\n",
        "from nltk.tokenize import RegexpTokenizer \n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.decomposition import LatentDirichletAllocation \n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# COVID SURVEY DATASET"
      ],
      "metadata": {
        "id": "Z8Z8EPtUszR7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read data from CSV file \n",
        "covid_survey = pd.read_csv('COVIDSurveydata.csv')\n",
        "# filter data by text_long column \n",
        "covid_survey['text_long']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GPcIun-mvsem",
        "outputId": "1f237b24-ed5a-4cb1-a29e-4d80ce8533cf"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       It is less an much an issue of how it affects ...\n",
              "1       I am concerned that the true impact of the cur...\n",
              "2       Personally, I am fairly calm about the corona ...\n",
              "3       In this very moment as I am fortunate to be ab...\n",
              "4       I am more worried about getting access to my n...\n",
              "                              ...                        \n",
              "2478    I feel sad for the loss of life and the pain t...\n",
              "2479    I fear  that  the virus is more deadly than  w...\n",
              "2480    I feel stressed and anxious about people ignor...\n",
              "2481    It is quite worrying even though it said to ha...\n",
              "2482    I feel helpless that in reality there's nothin...\n",
              "Name: text_long, Length: 2483, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# VECTORIZE THE DATA\n"
      ],
      "metadata": {
        "id": "_kD1QNtFR9NV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Vectorize survey using TF-IDF\n",
        "tfidf_vectorizer = TfidfVectorizer(lowercase=True,\n",
        "                            ngram_range = (1,2),\n",
        "                            #max_df=0.95, min_df=2, \n",
        "                            #max_features=n_features, \n",
        "                            stop_words=\"english\"\n",
        ")\n",
        "\n",
        "# Fit and Transform the documents\n",
        "X = tfidf_vectorizer.fit_transform(covid_survey['text_long'])  \n",
        "\n",
        "# get the actual words from the vectorized data\n",
        "tf_feature_names = tfidf_vectorizer.get_feature_names_out()\n",
        "\n",
        "print(\"n_samples: %d, n_features: %d\" % X.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vZFrpK6nSE2U",
        "outputId": "e7a832ef-fccc-4811-ac9a-92cd99060784"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_samples: 2483, n_features: 82254\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PERFORM LDA"
      ],
      "metadata": {
        "id": "GvuapIukWoCH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the number of TOPICS or components\n",
        "# LDA topic modeling with 5 topics \n",
        "num_components=5\n",
        "\n",
        "# Create LDA object\n",
        "ldamodel=LatentDirichletAllocation(n_components=num_components)\n",
        "\n",
        "# Fit and Transform model on data that has already been vectorized\n",
        "lda_matrix = ldamodel.fit_transform(X)\n",
        "\n",
        "# Get Components from the lda model\n",
        "# components_[i, j] can be viewed as pseudocount that represents the number of \n",
        "# times word j was assigned to topic i. from scikit-learn\n",
        "lda_components=ldamodel.components_"
      ],
      "metadata": {
        "id": "hz05Cu1DWtZK"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# view the topic models\n",
        "n_top_words = 10 # how many words per topic\n",
        "\n",
        "for i, topic in enumerate(lda_components):\n",
        "    # numpy argsort: Returns the indices that would sort an array\n",
        "    # we want the last n_top_words indices, as they have the highest counts \n",
        "    \n",
        "    top_features_index = topic.argsort() [  :-n_top_words - 1 : -1 ]\n",
        "\n",
        "    # based on indices, get the words, from the vectorizer features\n",
        "    top_features = [tf_feature_names[i] for i in top_features_index]\n",
        "    print('topic', i, top_features)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oj2TjI2BYHK5",
        "outputId": "33c7dec1-2002-4eaa-b5d3-394a77ef8cce"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "topic 0 ['people', 'feel', 'family', 'situation', 'virus', 'worried', 'anxious', 'going', 'time', 'think']\n",
            "topic 1 ['feel', 'people', 'worried', 'family', 'situation', 'time', 'virus', 'home', 'anxious', 'work']\n",
            "topic 2 ['feel', 'people', 'worried', 'family', 'time', 'situation', 'virus', 'home', 'anxious', 'government']\n",
            "topic 3 ['people', 'feel', 'worried', 'situation', 'family', 'time', 'virus', 'anxious', 'don', 'going']\n",
            "topic 4 ['feel', 'people', 'worried', 'family', 'situation', 'home', 'time', 'virus', 'work', 'anxious']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **UNIGRAM**"
      ],
      "metadata": {
        "id": "mWZ3ch5fXTGs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.util import ngrams \n",
        "covid_survey = pd.read_csv('COVIDSurveydata.csv')\n",
        "covid_survey['text_long']\n",
        "n = 1\n",
        "unigrams = ngrams(covid_survey, n)\n",
        "for item in unigrams: \n",
        "  print(item)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HUqOfYJ8Xahq",
        "outputId": "6c2fb5af-8c4d-4190-c09c-766d8a4349ff"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('Unnamed: 0',)\n",
            "('V1',)\n",
            "('worry',)\n",
            "('chosen_emotion',)\n",
            "('anger',)\n",
            "('disgust',)\n",
            "('fear',)\n",
            "('anxiety',)\n",
            "('sadness',)\n",
            "('happiness',)\n",
            "('relaxation',)\n",
            "('desire',)\n",
            "('text_long',)\n",
            "('timing_textlong_firstclick',)\n",
            "('timing_textlong_lastclick',)\n",
            "('timing_textlong_submit',)\n",
            "('timing_textlong_nclicks',)\n",
            "('text_short',)\n",
            "('timing_textshort_firstclick',)\n",
            "('timing_textshort_lastclick',)\n",
            "('timing_textshort_submit',)\n",
            "('timing_textshort_nclicks',)\n",
            "('self_rating_general',)\n",
            "('self_rating_short',)\n",
            "('self_rating_long',)\n",
            "('twitter_general_often',)\n",
            "('twitter_tweet_often',)\n",
            "('twitter_participate_often',)\n",
            "('eng_native',)\n",
            "('ntok_long',)\n",
            "('nchar_long',)\n",
            "('ntok_short',)\n",
            "('nchar_short',)\n",
            "('cld_lang_long',)\n",
            "('cld_lang_short',)\n",
            "('id',)\n",
            "('n_punct',)\n",
            "('prop_punct',)\n",
            "('age',)\n",
            "('Country of Birth',)\n",
            "('Current Country of Residence',)\n",
            "('Employment Status',)\n",
            "('First Language',)\n",
            "('Nationality',)\n",
            "('Sex',)\n",
            "('Social-Media',)\n",
            "('Student Status',)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "\n",
        "# TRIGRAM"
      ],
      "metadata": {
        "id": "OMQC1MbUeiiw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.util import ngrams \n",
        "covid_survey = pd.read_csv('COVIDSurveydata.csv')\n",
        "covid_survey['text_long']\n",
        "n = 3\n",
        "unigrams = ngrams(covid_survey, n)\n",
        "for item in unigrams: \n",
        "  print(item)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_8LXzoFXepyx",
        "outputId": "5a161fd7-f1bc-4dd6-a308-1beeb994854b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('Unnamed: 0', 'V1', 'worry')\n",
            "('V1', 'worry', 'chosen_emotion')\n",
            "('worry', 'chosen_emotion', 'anger')\n",
            "('chosen_emotion', 'anger', 'disgust')\n",
            "('anger', 'disgust', 'fear')\n",
            "('disgust', 'fear', 'anxiety')\n",
            "('fear', 'anxiety', 'sadness')\n",
            "('anxiety', 'sadness', 'happiness')\n",
            "('sadness', 'happiness', 'relaxation')\n",
            "('happiness', 'relaxation', 'desire')\n",
            "('relaxation', 'desire', 'text_long')\n",
            "('desire', 'text_long', 'timing_textlong_firstclick')\n",
            "('text_long', 'timing_textlong_firstclick', 'timing_textlong_lastclick')\n",
            "('timing_textlong_firstclick', 'timing_textlong_lastclick', 'timing_textlong_submit')\n",
            "('timing_textlong_lastclick', 'timing_textlong_submit', 'timing_textlong_nclicks')\n",
            "('timing_textlong_submit', 'timing_textlong_nclicks', 'text_short')\n",
            "('timing_textlong_nclicks', 'text_short', 'timing_textshort_firstclick')\n",
            "('text_short', 'timing_textshort_firstclick', 'timing_textshort_lastclick')\n",
            "('timing_textshort_firstclick', 'timing_textshort_lastclick', 'timing_textshort_submit')\n",
            "('timing_textshort_lastclick', 'timing_textshort_submit', 'timing_textshort_nclicks')\n",
            "('timing_textshort_submit', 'timing_textshort_nclicks', 'self_rating_general')\n",
            "('timing_textshort_nclicks', 'self_rating_general', 'self_rating_short')\n",
            "('self_rating_general', 'self_rating_short', 'self_rating_long')\n",
            "('self_rating_short', 'self_rating_long', 'twitter_general_often')\n",
            "('self_rating_long', 'twitter_general_often', 'twitter_tweet_often')\n",
            "('twitter_general_often', 'twitter_tweet_often', 'twitter_participate_often')\n",
            "('twitter_tweet_often', 'twitter_participate_often', 'eng_native')\n",
            "('twitter_participate_often', 'eng_native', 'ntok_long')\n",
            "('eng_native', 'ntok_long', 'nchar_long')\n",
            "('ntok_long', 'nchar_long', 'ntok_short')\n",
            "('nchar_long', 'ntok_short', 'nchar_short')\n",
            "('ntok_short', 'nchar_short', 'cld_lang_long')\n",
            "('nchar_short', 'cld_lang_long', 'cld_lang_short')\n",
            "('cld_lang_long', 'cld_lang_short', 'id')\n",
            "('cld_lang_short', 'id', 'n_punct')\n",
            "('id', 'n_punct', 'prop_punct')\n",
            "('n_punct', 'prop_punct', 'age')\n",
            "('prop_punct', 'age', 'Country of Birth')\n",
            "('age', 'Country of Birth', 'Current Country of Residence')\n",
            "('Country of Birth', 'Current Country of Residence', 'Employment Status')\n",
            "('Current Country of Residence', 'Employment Status', 'First Language')\n",
            "('Employment Status', 'First Language', 'Nationality')\n",
            "('First Language', 'Nationality', 'Sex')\n",
            "('Nationality', 'Sex', 'Social-Media')\n",
            "('Sex', 'Social-Media', 'Student Status')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GENDER"
      ],
      "metadata": {
        "id": "BXZesB8_mMzJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read data from CSV file \n",
        "covid_survey = pd.read_csv('COVIDSurveydata.csv')\n",
        "# filter data by Sex column \n",
        "covid_survey['Sex']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nw2tNQwymTV6",
        "outputId": "f7a861a6-e881-4893-f65b-e552c1f21d59"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0          NaN\n",
              "1          NaN\n",
              "2          NaN\n",
              "3       Female\n",
              "4       Female\n",
              "         ...  \n",
              "2478       NaN\n",
              "2479       NaN\n",
              "2480       NaN\n",
              "2481       NaN\n",
              "2482       NaN\n",
              "Name: Sex, Length: 2483, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    }
  ]
}